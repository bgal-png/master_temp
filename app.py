import streamlit as st
import pandas as pd
import os
import io
import re
from difflib import get_close_matches

# 1. Page Configuration
st.set_page_config(page_title="Excel Validator v2", layout="wide")
st.title("Excel Validator: Glasses Edition üëì")

# --- COLUMN MAPPING CONFIGURATION ---
# These are the "Ideal" names we want to find.
# The code will now search for the BEST match in your file for each of these.
TARGET_COLUMNS = {
    "Glasses type": "Glasses type ID: 13",
    "Manufacturer": "Manufacturer ID: 9",
    "Glasses size: glasses width": "Glasses size: glasses width ID: 69",
    "Glasses size: temple length": "Glasses size: temple length ID: 70",
    "Glasses size: lens height": "Glasses size: lens height ID: 71",
    "Glasses size: lens width": "Glasses size: lens width ID: 72",
    "Glasses size: bridge": "Glasses size: bridge ID: 73",
    "Glasses shape": "Glasses shape ID: 25",
    "Glasses other info": "Glasses other info ID: 49",
    "Glasses frame type": "Glasses frame type ID: 50",
    "Glasses frame color": "Frame Colour ID: 26",
    "Glasses temple color": "Temple Colour ID: 39",
    "Glasses main material": "Glasses main material ID: 53",
    "Glasses lens color": "Glasses lens Colour ID: 28",
    "Glasses lens material": "Glasses lens material ID: 35",
    "Glasses lens effect": "Glasses lens effect ID: 37",
    "Sunglasses filter": "Sunglasses filter ID: 77",
    "Glasses genre": "Glasses gendre ID: 22",
    "Glasses usable": "Glasses usable ID: 51",
    "Glasses collection": "Glasses collection ID: 33",
    "UV filter": "UV filter ID: 60",
    "Items type": "Items type ID: 20",
    "Items packing": "Items packing ID: 21",
    "Glasses contain": "Glasses contain ID: 84",
    "Sport glasses": "Sports Glasses ID: 89",
    "Glasses frame color effect": "Glasses frame color effect ID: 92",
    "Glasses other features": "Glasses other features ID:99",
    "SunGlasses RX lenses": "SunGlasses RX lenses ID:108",
    "Glasses clip-on lens color": "Glasses clip-on lens colour ID:112",
    "Brand": "Brand ID:11",
    "Producing company": "Producing company ID:146",
    "Glasses for your face shape": "Glasses for your face shape ID:94",
    "Glasses lenses no-orders": "Glasses lenses no-orders ID:103"
}

# --- HELPER: NORMALIZE HEADERS ---
def normalize_text(text):
    """
    Aggressive cleaner: removes all non-alphanumeric characters (except :) 
    and lowercases everything to find a match.
    """
    if not isinstance(text, str): return str(text)
    # Replace newlines/tabs with space
    text = re.sub(r'\s+', ' ', text)
    return text.strip()

@st.cache_data
def load_master():
    """Smart Loader: Scans folder for ANY Excel/CSV file."""
    current_dir = os.getcwd()
    candidates = [f for f in os.listdir(current_dir) if (f.endswith('.xlsx') or f.endswith('.csv')) and "mistakes" not in f and not f.startswith('~$')]
    
    if not candidates:
        st.error("‚ùå No Master File found!"); st.stop()
    
    file_path = candidates[0]
    df = None
    
    try:
        if file_path.endswith('.csv'):
            for enc in ['utf-8', 'cp1252', 'latin1']:
                try: df = pd.read_csv(file_path, dtype=str, sep=None, engine='python', encoding=enc); break
                except: continue
        else:
            df = pd.read_excel(file_path, dtype=str, engine='openpyxl')
    except Exception as e:
        st.error(f"‚ùå Failed to load '{file_path}': {e}"); st.stop()
        
    if df is None: st.error("‚ùå Could not read file."); st.stop()

    # Normalization
    df.columns = [normalize_text(c) for c in df.columns]
    
    # Check for 'Items type'
    # We use fuzzy matching even for the Master file
    matches = get_close_matches("Items type", df.columns, n=1, cutoff=0.6)
    if matches:
        return df[df[matches[0]] == "Glasses"]
    else:
        st.error(f"‚ùå 'Items type' missing in Master. Found: {list(df.columns)}"); st.stop()

def clean_user_file(file, header_row=0):
    try:
        df = pd.read_excel(file, dtype=str, header=header_row)
    except:
        file.seek(0)
        df = pd.read_csv(file, dtype=str, sep=None, engine='python', header=header_row)
    
    # Normalize Headers
    df.columns = [normalize_text(c) for c in df.columns]
    return df

# 2. LOAD MASTER
master_df = load_master()
st.success(f"‚úÖ Master File Loaded ({len(master_df)} rows).")

# 3. UPLOAD SECTION
st.divider()
st.subheader("1. Upload File")

col_upload, col_settings = st.columns([2, 1])
with col_settings:
    header_row_idx = st.number_input("Header Row Number", min_value=0, max_value=10, value=0)
with col_upload:
    uploaded_file = st.file_uploader("Choose Excel File", type=['xlsx'])

if uploaded_file:
    user_df = clean_user_file(uploaded_file, header_row=header_row_idx)
    st.info(f"User file loaded: {len(user_df)} rows.")

    # 4. SMART MAPPING (The Fix)
    # We dynamically build the map based on what we find in the file
    final_map = {}
    missing_cols = []
    
    user_cols = list(user_df.columns)
    
    st.write("---")
    st.subheader("üîç Column Matching Report")
    
    # Loop through our "Wishlist" of columns
    for master_name, ideal_user_name in TARGET_COLUMNS.items():
        
        # 1. Try Exact Match (Normalized)
        if ideal_user_name in user_cols:
            final_map[master_name] = ideal_user_name
            continue
            
        # 2. Try Fuzzy Match (Is there something very similar?)
        # cutoff=0.6 means "60% similar"
        matches = get_close_matches(ideal_user_name, user_cols, n=1, cutoff=0.6)
        
        if matches:
            found_col = matches[0]
            final_map[master_name] = found_col
            # Optional: Show what we found
            # st.caption(f"‚úÖ Mapped '{ideal_user_name}' -> '{found_col}'")
        else:
            missing_cols.append(ideal_user_name)

    # CHECK FOR CRITICAL MISSING COLUMNS
    if missing_cols:
        st.error(f"‚ùå CRITICAL: Could not find these columns (even with fuzzy search):")
        st.write(missing_cols)
        st.write("Available columns in your file:", user_cols)
        st.stop()

    st.success(f"‚úÖ All {len(final_map)} columns mapped successfully!")

    # 5. VALIDATION LOGIC
    if st.button("üöÄ Run Validation"):
        mistakes = []
        st.write("Checking data... please wait.")
        
        valid_values = {}
        # Pre-load Master Values (using fuzzy matched column names if needed)
        master_cols = list(master_df.columns)
        
        for master_key in final_map.keys():
            # Find the actual column name in Master
            match = get_close_matches(master_key, master_cols, n=1, cutoff=0.6)
            if match:
                real_master_col = match[0]
                valid_set = set(master_df[real_master_col].dropna().astype(str).str.strip().str.lower())
                valid_values[master_key] = valid_set
            else:
                st.error(f"Could not find '{master_key}' in Master File"); st.stop()

        progress_bar = st.progress(0)
        total_rows = len(user_df)
        
        for index, row in user_df.iterrows():
            if index % 10 == 0: progress_bar.progress(min(index / total_rows, 1.0))
            
            for master_key, user_col_name in final_map.items():
                cell_value = str(row[user_col_name]).strip()
                if cell_value.lower() in ['nan', '', 'none']: continue
                
                # Validation
                if cell_value.lower() not in valid_values[master_key]:
                    mistakes.append({
                        "Row #": index + 2 + header_row_idx,
                        "Column": user_col_name,
                        "Invalid Value": cell_value,
                        "Allowed Options (Example)": list(valid_values[master_key])[:3]
                    })

        progress_bar.empty()

        if mistakes:
            st.error(f"Found {len(mistakes)} Invalid Values!")
            results_df = pd.DataFrame(mistakes)
            st.dataframe(results_df, use_container_width=True)
            
            buffer = io.BytesIO()
            with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:
                results_df.to_excel(writer, index=False)
            st.download_button("üì• Download Error Report", buffer, "validation_errors.xlsx")
        else:
            st.balloons()
            st.success("‚úÖ Amazing! No invalid values found.")
